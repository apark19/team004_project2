{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import sklearn\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.under_sampling import ClusterCentroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V21       V22  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
      "\n",
      "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
      "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
      "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
      "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
      "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
      "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
      "...          ...       ...       ...       ...       ...       ...     ...   \n",
      "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
      "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
      "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
      "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
      "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
      "\n",
      "        Class  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "...       ...  \n",
      "284802      0  \n",
      "284803      0  \n",
      "284804      0  \n",
      "284805      0  \n",
      "284806      0  \n",
      "\n",
      "[284807 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "cc_df=pd.read_csv(\"creditcard.csv\")\n",
    "print(cc_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Time         V1         V2        V3        V4        V5  \\\n",
      "0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n",
      "1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n",
      "2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n",
      "3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n",
      "4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n",
      "...          ...        ...        ...       ...       ...       ...   \n",
      "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
      "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
      "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
      "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
      "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
      "\n",
      "              V6        V7        V8        V9  ...       V20       V21  \\\n",
      "0       0.462388  0.239599  0.098698  0.363787  ...  0.251412 -0.018307   \n",
      "1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.069083 -0.225775   \n",
      "2       1.800499  0.791461  0.247676 -1.514654  ...  0.524980  0.247998   \n",
      "3       1.247203  0.237609  0.377436 -1.387024  ... -0.208038 -0.108300   \n",
      "4       0.095921  0.592941 -0.270533  0.817739  ...  0.408542 -0.009431   \n",
      "...          ...       ...       ...       ...  ...       ...       ...   \n",
      "284802 -2.606837 -4.918215  7.305334  1.914428  ...  1.475829  0.213454   \n",
      "284803  1.058415  0.024330  0.294869  0.584800  ...  0.059616  0.214205   \n",
      "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.001396  0.232045   \n",
      "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.127434  0.265245   \n",
      "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.382948  0.261057   \n",
      "\n",
      "             V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0       0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053   \n",
      "1      -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724   \n",
      "2       0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752   \n",
      "3       0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458   \n",
      "4       0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "284802  0.111864  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731   \n",
      "284803  0.924384  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   \n",
      "284804  0.578229 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   \n",
      "284805  0.800049 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   \n",
      "284806  0.643078  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649   \n",
      "\n",
      "        Amount  \n",
      "0       149.62  \n",
      "1         2.69  \n",
      "2       378.66  \n",
      "3       123.50  \n",
      "4        69.99  \n",
      "...        ...  \n",
      "284802    0.77  \n",
      "284803   24.79  \n",
      "284804   67.88  \n",
      "284805   10.00  \n",
      "284806  217.00  \n",
      "\n",
      "[284807 rows x 30 columns]\n",
      "        Class\n",
      "0           0\n",
      "1           0\n",
      "2           0\n",
      "3           0\n",
      "4           0\n",
      "...       ...\n",
      "284802      0\n",
      "284803      0\n",
      "284804      0\n",
      "284805      0\n",
      "284806      0\n",
      "\n",
      "[284807 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split into Train / Test Sets\n",
    "x=cc_df.drop(columns='Class',axis=1)\n",
    "print(x)\n",
    "\n",
    "y=cc_df[['Class']].copy()\n",
    "print(y)\n",
    "\n",
    "xtrain,xtest,ytrain,ytest=train_test_split(x,y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Time         V1        V2         V3        V4        V5  \\\n",
      "0       159708.000000  -0.459482  1.198230   2.315423  4.274698  0.603004   \n",
      "1       129139.000000   1.878563  0.020785  -1.621113  2.908813  2.507847   \n",
      "2         4263.000000  -1.467414  1.210542   1.891733 -0.282189 -0.214526   \n",
      "3       113041.000000   2.073474 -0.147624  -1.495803  0.184499  0.107505   \n",
      "4        77352.000000   1.097497  0.357207   1.051187  2.631217 -0.464023   \n",
      "...               ...        ...       ...        ...       ...       ...   \n",
      "426443   41233.586829 -10.355998  6.092424 -13.081348  7.333507 -9.550066   \n",
      "426444   35886.873089  -2.813944  3.771450  -3.775914  5.561832 -3.589699   \n",
      "426445  143237.936649  -1.408302  2.508873  -2.686728  4.111950  0.516272   \n",
      "426446  129738.321857  -1.581447  2.974258  -6.213306  3.656808 -0.810412   \n",
      "426447  150719.013410  -0.261952  1.361121  -2.416682  3.613812  0.951105   \n",
      "\n",
      "              V6         V7        V8        V9  ...       V20       V21  \\\n",
      "0       2.280395   0.026612  0.564397 -1.726571  ...  0.340961 -0.351269   \n",
      "1       4.709442  -0.830626  1.136154 -0.395755  ... -0.252053  0.079998   \n",
      "2      -0.201625   1.547764 -0.284276  0.907166  ... -0.545067 -0.039093   \n",
      "3      -0.858107   0.046284 -0.179913  0.984100  ... -0.330026  0.250739   \n",
      "4      -0.006905  -0.183556  0.166381 -0.456974  ... -0.209872 -0.232654   \n",
      "...          ...        ...       ...       ...  ...       ...       ...   \n",
      "426443 -3.575736 -13.240398  6.703594 -6.412760  ...  0.052724  2.323254   \n",
      "426444 -1.072124  -6.234514  2.191212 -4.577886  ...  1.000720  1.535235   \n",
      "426445 -0.855586  -1.482650  1.030846 -2.824361  ... -0.013534  0.469663   \n",
      "426446 -1.626558  -0.531045  0.443097 -1.722749  ... -0.129052  0.076182   \n",
      "426447 -1.138472  -1.300772 -1.055883 -0.936001  ...  0.029243 -0.541755   \n",
      "\n",
      "             V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0      -0.906878 -0.131385  0.050282  0.029694  0.144998  0.114877  0.093615   \n",
      "1       0.404327  0.121098  0.707538  0.140100  0.155684  0.016375 -0.053892   \n",
      "2       0.097313 -0.302656  0.320926  0.586090 -0.631388 -0.298853  0.016153   \n",
      "3       0.802850  0.034933  0.655414  0.289638 -0.442057 -0.003265 -0.051052   \n",
      "4      -0.626643  0.106893  0.486223  0.296727 -0.207474  0.001507  0.016926   \n",
      "...          ...       ...       ...       ...       ...       ...       ...   \n",
      "426443 -0.219565 -0.187031  0.489659 -0.012570  0.446532  0.262011 -0.315722   \n",
      "426444  0.805297 -0.141818 -0.001434 -0.001580  0.375170  1.091865  0.552527   \n",
      "426445 -0.022696 -0.272986 -0.104241 -0.001423 -0.056774  0.339506  0.121913   \n",
      "426446 -0.297973  0.165530 -0.427767  0.212668 -0.324524  0.386898 -0.252623   \n",
      "426447  0.366895 -0.075274 -0.375881  0.177356 -0.055517  0.095627  0.164968   \n",
      "\n",
      "            Amount  \n",
      "0        27.230000  \n",
      "1         0.000000  \n",
      "2       153.000000  \n",
      "3         1.000000  \n",
      "4         3.930000  \n",
      "...            ...  \n",
      "426443   37.043120  \n",
      "426444    8.403177  \n",
      "426445    0.585490  \n",
      "426446  266.109848  \n",
      "426447    5.099695  \n",
      "\n",
      "[426448 rows x 30 columns]\n",
      "        Class\n",
      "0           0\n",
      "1           0\n",
      "2           0\n",
      "3           0\n",
      "4           0\n",
      "...       ...\n",
      "426443      1\n",
      "426444      1\n",
      "426445      1\n",
      "426446      1\n",
      "426447      1\n",
      "\n",
      "[426448 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Oversampling (Smote) + Random Forest \n",
    "xsmote,ysmote=SMOTE(random_state=1,sampling_strategy=1.0).fit_resample(xtrain,ytrain)\n",
    "\n",
    "print(xsmote)\n",
    "print(ysmote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xgb=xgb.XGBClassifier(\n",
    "    learning_rate=0.001,\n",
    "    max_depth=2,\n",
    "    n_estimators=100,\n",
    "    scale_pos_weight=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:13:13] WARNING: /private/var/folders/tn/scrc7fy54771ngyq24hw419m0000gn/T/pip-install-fp4t23h0/xgboost/build/temp.macosx-10.9-x86_64-3.8/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.001, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=5, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(xsmote,ysmote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.88      0.94      0.93      0.91      0.82     71091\n",
      "          1       0.01      0.94      0.88      0.02      0.91      0.83       111\n",
      "\n",
      "avg / total       1.00      0.88      0.94      0.93      0.91      0.82     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pred=xgb.predict(xtest)\n",
    "print(classification_report_imbalanced(ytest,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[62332  8759]\n",
      " [    7   104]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(ytest,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination Sampling + XGBoost\n",
    "smote_enn=SMOTEENN(random_state=0)\n",
    "xsmtn,ysmtn=smote_enn.fit_resample(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:20:03] WARNING: /private/var/folders/tn/scrc7fy54771ngyq24hw419m0000gn/T/pip-install-fp4t23h0/xgboost/build/temp.macosx-10.9-x86_64-3.8/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.001, max_delta_step=0, max_depth=2,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=5, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb.fit(xsmtn,ysmtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.94      0.86      0.97      0.90      0.82     71091\n",
      "          1       0.02      0.86      0.94      0.05      0.90      0.81       111\n",
      "\n",
      "avg / total       1.00      0.94      0.86      0.97      0.90      0.82     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pred=xgb.predict(xtest)\n",
    "print(classification_report_imbalanced(ytest,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersampling + Random Forest\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "cc=ClusterCentroids(random_state=1)\n",
    "xcc,ycc=cc.fit_resample(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:26:42] WARNING: /private/var/folders/tn/scrc7fy54771ngyq24hw419m0000gn/T/pip-install-fp4t23h0/xgboost/build/temp.macosx-10.9-x86_64-3.8/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/xgboost/sklearn.py:892: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(xcc,ycc.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      0.40      0.95      0.57      0.62      0.36     71091\n",
      "          1       0.00      0.95      0.40      0.00      0.62      0.40       111\n",
      "\n",
      "avg / total       1.00      0.40      0.95      0.57      0.62      0.36     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_pred=xgb.predict(xtest)\n",
    "print(classification_report_imbalanced(ytest,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10:28:09] WARNING: /private/var/folders/tn/scrc7fy54771ngyq24hw419m0000gn/T/pip-install-fp4t23h0/xgboost/build/temp.macosx-10.9-x86_64-3.8/xgboost/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       1.00      1.00      0.77      1.00      0.87      0.78     71091\n",
      "          1       0.57      0.77      1.00      0.66      0.87      0.75       111\n",
      "\n",
      "avg / total       1.00      1.00      0.77      1.00      0.87      0.78     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# No sampling\n",
    "xgb.fit(xtrain,ytrain.values.ravel())\n",
    "xgb_pred=xgb.predict(xtest)\n",
    "print(classification_report_imbalanced(ytest,xgb_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
